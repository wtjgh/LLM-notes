# BaseDatasetç±»
```python
class BaseDataset(torch.utils.data.Dataset):

    def __init__(self,
                 path: str,
                 model_name=None,
                 tokenizer=None,
                 preprocess=None) -> None:
        
        load_data = self.load(path)
        self.datalist  = load_data["data"]
        self.labellist = load_data["label"]
        if model_name is None and tokenizer is None:
            raise ValueError('model_name and tokenizer could not both be None')
        if tokenizer is not None:
            self.tokenizer = tokenizer
        else:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.tokenizer.pad_token = self.tokenizer.eos_token
            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
            self.tokenizer.padding_side = 'left'
        self.datalist_length = len(self.datalist)
        self.preprocess = preprocess

    def __len__(self):
        return self.datalist_length

    def __getitem__(self, idx):
        data,label = self.preprocess(self.datalist[idx],self.labellist[idx])
        tokenized_data = self.tokenizer.encode_plus(data,
                                                        truncation=True,
                                                        return_tensors='pt',
                                                        verbose=False)
        tokenized_label = self.tokenizer.encode_plus(label,
                                                        truncation=True,
                                                        return_tensors='pt',
                                                        verbose=False)
        ret = dict(
            input_ids=tokenized_data.input_ids[0],
            labels=tokenized_label.input_ids[0],
            attention_mask=tokenized_data.attention_mask[0] ,
        )
        return ret

    @abstractstaticmethod
    def load(self, path : str) -> Union[Dataset, DatasetDict]:
        pass
```
