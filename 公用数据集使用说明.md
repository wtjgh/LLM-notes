# BaseDataset类
```python
class BaseDataset(torch.utils.data.Dataset):

    def __init__(self,
                 path: str,
                 model_name=None,
                 tokenizer=None,
                 preprocess=None) -> None:
        
        load_data = self.load(path)
        self.datalist  = load_data["data"]
        self.labellist = load_data["label"]
        if model_name is None and tokenizer is None:
            raise ValueError('model_name and tokenizer could not both be None')
        if tokenizer is not None:
            self.tokenizer = tokenizer
        else:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.tokenizer.pad_token = self.tokenizer.eos_token
            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
            self.tokenizer.padding_side = 'left'
        self.datalist_length = len(self.datalist)
        self.preprocess = preprocess

    def __len__(self):
        return self.datalist_length

    def __getitem__(self, idx):
        data,label = self.preprocess(self.datalist[idx],self.labellist[idx])
        tokenized_data = self.tokenizer.encode_plus(data,
                                                        truncation=True,
                                                        return_tensors='pt',
                                                        verbose=False)
        tokenized_label = self.tokenizer.encode_plus(label,
                                                        truncation=True,
                                                        return_tensors='pt',
                                                        verbose=False)
        ret = dict(
            input_ids=tokenized_data.input_ids[0],
            labels=tokenized_label.input_ids[0],
            attention_mask=tokenized_data.attention_mask[0] ,
        )
        return ret

    @abstractstaticmethod
    def load(self, path : str) -> Union[Dataset, DatasetDict]:
        pass
```
如上面代码所示，BaseDataset主要需要使用者传递三个参数，分别为：
 - `path`：数据集保存的路径，会传递给load函数加载数据集。需要注意的是：**由于数据集存储格式都不相同。因此，对于每一个新的数据集都需要重载load函数，并且load函数的返回要符合要求。这会在下一小节详细描述。**
 - `tokenizer`：模型对应的tokenizer。
 - `preprocess`模型对应的预处理方式。
# load函数
我们以华佗数据集为例，说明如何重载一个新的数据集对应的load函数
```python
class HTGenDataset(BaseDataset):

    @staticmethod
    def load(path: str):
        src_path = path
        with open(src_path, 'r', encoding='utf-8') as file:
            data = json.load(file)

        result_dict = {'data': [], 'label': []}

        for item in data:
            conversations = item.get('conversations', [])
            # result_dict = {'content': [], 'target': []}
            
            for conversation in conversations:
                if conversation['from'] == 'user':
                    result_dict['data'].append(conversation['value'])
                elif conversation['from'] == 'assistant':
                    result_dict['label'].append(conversation['value'])

        dataset = Dataset.from_dict({
            'data': result_dict['data'],
            'label': result_dict['label']
        })
        return dataset
```
如上所示，为了减少重复工作。在定义BaseDataset时我们尽量增加可以复用的代码，因此，对于一个新的数据集，我们只需重载load函数即可完成一个新的数据集的定义。
如代码所示，load函数通过path参数获取数据集的路径，然后读取对应数据集。随后对数据集进行一些处理，使得返回的值为数据列表和label列表。为了方便，我们使用一个字典将他们包了起来。
注意：**为了能够复用BaseDataset类中其他代码，返回值必须严格按照定义好的格式来。**
